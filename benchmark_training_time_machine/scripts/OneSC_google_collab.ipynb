{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTp-tmmDeu1L",
        "outputId": "21ae8741-1060-45f2-f2a1-bb0854c8c56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/CahanLab/oneSC.git\n",
            "  Cloning https://github.com/CahanLab/oneSC.git to /tmp/pip-req-build-s_1p35kb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/CahanLab/oneSC.git /tmp/pip-req-build-s_1p35kb\n",
            "  Resolved https://github.com/CahanLab/oneSC.git to commit dacd08d8f750d10e3c4685b394ed046d9fd4ba7c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from onesc==0.1.1) (8.1.7)\n",
            "Collecting pygad>=3.1.0 (from onesc==0.1.1)\n",
            "  Downloading pygad-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pygam>=0.8.0 (from onesc==0.1.1)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from onesc==0.1.1) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from onesc==0.1.1) (2.1.4)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from onesc==0.1.1) (0.14.2)\n",
            "Collecting scipy<1.12.0,>=1.8.0 (from onesc==0.1.1)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scanpy>=1.9.1 (from onesc==0.1.1)\n",
            "  Downloading scanpy-1.10.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: joblib>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from onesc==0.1.1) (1.4.2)\n",
            "Collecting networkx<=3.2.1,>=2.8.8 (from onesc==0.1.1)\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting adjustText>=1.1.1 (from onesc==0.1.1)\n",
            "  Downloading adjustText-1.2.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting igraph>=0.11.5 (from onesc==0.1.1)\n",
            "  Downloading igraph-0.11.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from adjustText>=1.1.1->onesc==0.1.1) (3.7.1)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.11.5->onesc==0.1.1)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->onesc==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->onesc==0.1.1) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->onesc==0.1.1) (2024.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pygad>=3.1.0->onesc==0.1.1) (2.2.1)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pygam>=0.8.0->onesc==0.1.1) (4.2.0)\n",
            "Collecting anndata>=0.8 (from scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading anndata-0.10.8-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (3.11.0)\n",
            "Collecting legacy-api-wrap>=1.4 (from scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading legacy_api_wrap-1.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (8.4.0)\n",
            "Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (0.60.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (24.1)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (0.5.6)\n",
            "Collecting pynndescent>=0.5 (from scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (1.3.2)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (0.13.1)\n",
            "Collecting session-info (from scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.9.1->onesc==0.1.1) (4.66.5)\n",
            "Collecting umap-learn!=0.5.0,>=0.5 (from scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading array_api_compat-1.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy>=1.9.1->onesc==0.1.1) (1.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText>=1.1.1->onesc==0.1.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText>=1.1.1->onesc==0.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText>=1.1.1->onesc==0.1.1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText>=1.1.1->onesc==0.1.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText>=1.1.1->onesc==0.1.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->adjustText>=1.1.1->onesc==0.1.1) (3.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy>=1.9.1->onesc==0.1.1) (0.43.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy>=1.9.1->onesc==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam>=0.8.0->onesc==0.1.1) (3.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy>=1.9.1->onesc==0.1.1) (3.5.0)\n",
            "Collecting stdlib_list (from session-info->scanpy>=1.9.1->onesc==0.1.1)\n",
            "  Downloading stdlib_list-0.10.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2<5.0.0,>=4.2.0->pygam>=0.8.0->onesc==0.1.1) (4.12.2)\n",
            "Downloading adjustText-1.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading igraph-0.11.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygad-3.3.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scanpy-1.10.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.10.8-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n",
            "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading array_api_compat-1.8-py3-none-any.whl (38 kB)\n",
            "Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: onesc, session-info\n",
            "  Building wheel for onesc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onesc: filename=onesc-0.1.1-py3-none-any.whl size=29389 sha256=97955593f94d630e6f1ee216de9f9f2686fa47176ae3834041ee9c12a4b92939\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jpzg5pdy/wheels/eb/0a/8f/0611d2e682dd658fcc339b9315df21dee7b89901727dbc0920\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8023 sha256=5bf47c86d908e7e642ba1760493765b6c7eb4bde37bcf82c55aab44adfb08e2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
            "Successfully built onesc session-info\n",
            "Installing collected packages: texttable, array-api-compat, stdlib_list, scipy, networkx, legacy-api-wrap, igraph, session-info, pynndescent, pygam, pygad, anndata, adjustText, umap-learn, scanpy, onesc\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "xgboost 2.1.1 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adjustText-1.2.0 anndata-0.10.8 array-api-compat-1.8 igraph-0.11.6 legacy-api-wrap-1.4 networkx-3.2.1 onesc-0.1.1 pygad-3.3.1 pygam-0.9.1 pynndescent-0.5.13 scanpy-1.10.2 scipy-1.11.4 session-info-1.0.0 stdlib_list-0.10.0 texttable-1.7.0 umap-learn-0.5.6\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/CahanLab/oneSC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdh3kGdkq9Vr",
        "outputId": "6a47bb16-9db5-44e4-9e04-83ed965eae69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cairocffi\n",
            "  Downloading cairocffi-1.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi) (2.22)\n",
            "Downloading cairocffi-1.7.1-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cairocffi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDt38BBosSBa",
        "outputId": "383ecceb-3549-46fd-9076-8831a8c3b425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycairo\n",
            "  Using cached pycairo-1.26.1.tar.gz (346 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycairo\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pycairo \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pycairo (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pycairo\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pycairo\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pycairo)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pycairo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm_joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG3-qDK8Aeqj",
        "outputId": "3548ae8a-1e4b-40ec-a3c0-42a03603e9d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm_joblib\n",
            "  Downloading tqdm_joblib-0.0.4-py3-none-any.whl.metadata (269 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tqdm_joblib) (4.66.5)\n",
            "Downloading tqdm_joblib-0.0.4-py3-none-any.whl (1.7 kB)\n",
            "Installing collected packages: tqdm_joblib\n",
            "Successfully installed tqdm_joblib-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS2z6BJLfaDF"
      },
      "source": [
        "This is Method 1 of inferring networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibxRA8Mge6ZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d3800c-88b3-437b-b716-92c661228e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import onesc\n",
        "import networkx as nx\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IbC0YvpLuf0b"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J0eer_FrfH8w"
      },
      "outputs": [],
      "source": [
        "train_exp = pd.read_csv(\"https://cnobjects.s3.amazonaws.com/OneSC/Pual_2015/train_exp.csv\", index_col = 0)\n",
        "samp_tab = pd.read_csv(\"https://cnobjects.s3.amazonaws.com/OneSC/Pual_2015/samp_tab.csv\", index_col = 0)\n",
        "pt_col = 'dpt_pseudotime'\n",
        "cluster_col = 'cell_types'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eAywsHffn3R4"
      },
      "outputs": [],
      "source": [
        "initial_clusters = ['CMP']\n",
        "end_clusters = ['Erythrocytes', 'Granulocytes', 'Monocytes', 'MK']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U1hjMbt-n5Hc"
      },
      "outputs": [],
      "source": [
        "state_path = onesc.construct_cluster_network(train_exp, samp_tab, initial_clusters = initial_clusters, terminal_clusters = end_clusters, cluster_col = cluster_col, pseudo_col = pt_col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qTCTn-mkr5od"
      },
      "outputs": [],
      "source": [
        "lineage_cluster = onesc.extract_trajectory(state_path,initial_clusters, end_clusters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z4UqeQGVr7TG"
      },
      "outputs": [],
      "source": [
        "# find the boolean threshold for each gene\n",
        "vector_thresh = onesc.find_threshold_vector(train_exp, samp_tab, cluster_col = \"cell_types\", cutoff_percentage=0.4)\n",
        "\n",
        "# identify the finner time steps at which genes change along individual trajectory\n",
        "lineage_time_change_dict = onesc.find_gene_change_trajectory(train_exp, samp_tab, lineage_cluster, cluster_col, pt_col, vector_thresh, pseudoTime_bin=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dwupahLGsAK9"
      },
      "outputs": [],
      "source": [
        "# define boolean states profiles for each cell cluster\n",
        "state_dict = onesc.define_states(train_exp, samp_tab, lineage_cluster, vector_thresh, cluster_col, percent_exp = 0.3)\n",
        "\n",
        "# save the dictionary of Boolean states into a pickle object.\n",
        "# we will be needing the Boolean profiles of initial state for running simulations\n",
        "pickle.dump(state_dict, open(\"state_dict.pickle\", \"wb\"))\n",
        "\n",
        "# define transition profiles for each cell clusters\n",
        "transition_dict = onesc.define_transition(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCcHHi5tsGaM",
        "outputId": "9ae01b57-51ae-4189-d111-b32452fdbb72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cebpe have conflicting states, the below states are deleted\n",
            "['GMP_unstable_trajectory_1', 'GMP_stable_trajectory_2']\n",
            "Fli1 have conflicting states, the below states are deleted\n",
            "['CMP_stable_trajectory_0', 'CMP_stable_trajectory_1', 'CMP_stable_trajectory_2', 'CMP_unstable_trajectory_3']\n",
            "Gata1 have conflicting states, the below states are deleted\n",
            "['CMP_unstable_trajectory_0', 'CMP_stable_trajectory_1', 'CMP_stable_trajectory_2', 'CMP_stable_trajectory_3']\n",
            "Gata2 have conflicting states, the below states are deleted\n",
            "['CMP_stable_trajectory_0', 'CMP_unstable_trajectory_1', 'CMP_unstable_trajectory_2', 'CMP_stable_trajectory_3']\n",
            "Sox4 have conflicting states, the below states are deleted\n",
            "['CMP_stable_trajectory_1', 'CMP_stable_trajectory_2', 'CMP_unstable_trajectory_3']\n"
          ]
        }
      ],
      "source": [
        "# curate the training data for GRN inference for each gene\n",
        "training_data = onesc.curate_training_data(state_dict, transition_dict, lineage_time_change_dict, samp_tab, cluster_id = cluster_col, pt_id = pt_col,act_tolerance = 0.04)\n",
        "\n",
        "# calculate the pearson correlation between genes. This adds more information during the inference step.\n",
        "corr_mat = onesc.calc_corr(train_exp)\n",
        "ideal_edge_num = round(0.4 * corr_mat.shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv3sFqSHsIZh",
        "outputId": "1c39eac6-4675-4429-d0e4-ac41b6afca0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onesc/genetic_algorithm_GRN_trimming.py:845: UserWarning: Maximum number of cores is 2\n",
            "  warnings.warn(\"Maximum number of cores is \" + str(cpu_count()))\n",
            "Network inference ensemble (no parallelization): 100%|██████████| 25/25 [3:33:19<00:00, 511.98s/it]\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "grn_ensemble = onesc.create_network_ensemble(training_data,\n",
        "                                            corr_mat,\n",
        "                                            ideal_edges = ideal_edge_num,\n",
        "                                            num_generations = 300,\n",
        "                                            max_iter = 30,\n",
        "                                            num_parents_mating = 4,\n",
        "                                            run_parallel = False,\n",
        "                                            sol_per_pop = 30,\n",
        "                                            reduce_auto_reg = True,\n",
        "                                            GA_seed_list = [1, 2, 3, 4, 5],\n",
        "                                            init_pop_seed_list = [21, 22, 23, 24, 25]) # this would generate 25 networks (one for each GA, init seed combo)\n",
        "\n",
        "time_lapse = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dpAn_k9suuo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4c8a6a-03a9-422c-db95-4b4e5306173d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OneSC training takes 12800.893421649933\n"
          ]
        }
      ],
      "source": [
        "print(\"OneSC training takes \" + str(time_lapse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpZpEX4yuygE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}